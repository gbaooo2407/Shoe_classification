import os
os.environ['HF_HOME'] = 'D:/huggingface'
os.environ['TRANSFORMERS_CACHE'] = 'D:/huggingface_cache'

import streamlit as st
from PIL import Image
import torch
import torchvision.transforms as transforms
from text_generation import generate_caption  
from gradcam_visualize import apply_gradcam
from models import HybridResNetEfficientNet 

st.set_page_config(page_title="Chatbot Gi√†y D√©p üëü", layout="wide")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# H√†m d·ª± ƒëo√°n lo·∫°i gi√†y
def predict_shoe_type(image, model, device):
    transform = transforms.Compose([ 
        transforms.Resize((224, 224)), 
        transforms.ToTensor(), 
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    image_tensor = transform(image).unsqueeze(0).to(device, dtype=torch.float32)
    model.to(device) 
    model.eval()
    with torch.no_grad():
        logits = model(image_tensor)  # D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh
        predicted_class = torch.argmax(logits, dim=1).item()
    return predicted_class

# Load m√¥ h√¨nh Hybrid t·ª´ checkpoint ƒë√£ train
@st.cache_resource
def load_model():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = HybridResNetEfficientNet(num_classes=5).to(device)
    checkpoint_path = "best_model_hybrid.pth"
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint)
        model.eval()
        print(f"‚úÖ M√¥ h√¨nh ƒë√£ load th√†nh c√¥ng t·ª´: {checkpoint_path}")
    except Exception as e:
        print(f"L·ªói khi load m√¥ h√¨nh: {str(e)}")
    return model, device

hybrid_model, device = load_model()

st.title("üëü Chatbot Gi√†y D√©p - Nh·∫≠n Di·ªán & M√¥ T·∫£ S·∫£n Ph·∫©m")

st.sidebar.header("üñºÔ∏è T·∫£i l√™n ·∫£nh gi√†y c·ªßa b·∫°n")
uploaded_file = st.sidebar.file_uploader("Ch·ªçn ·∫£nh...", type=["jpg", "jpeg", "png"])

st.subheader("üí¨ Chatbot Ph√¢n T√≠ch H√¨nh ·∫¢nh")

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.sidebar.image(image, caption="üì∑ ·∫¢nh ƒë√£ t·∫£i l√™n", use_container_width=True)

    if st.sidebar.button("üîç Ph√¢n t√≠ch ·∫£nh"):
        with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω..."):
            try:
                # 1Ô∏è‚É£ D·ª± ƒëo√°n lo·∫°i gi√†y t·ª´ ·∫£nh b·∫±ng m√¥ h√¨nh Hybrid
                class_names = ['Boot', 'Sandal', 'Shoe', 'High Heel', 'Slipper']
                predicted_class = predict_shoe_type(image, hybrid_model, device)
                shoe_type = class_names[predicted_class]

                # 2Ô∏è‚É£ Sinh m√¥ t·∫£ b·∫±ng BLIP-2
                image_path = "temp_uploaded_image.jpg"
                image.save(image_path)  # L∆∞u ·∫£nh t·∫°m
                caption = generate_caption(image_path)

                # 3Ô∏è‚É£ √Åp d·ª•ng Grad-CAM++
                heatmap_path = apply_gradcam(image_path, hybrid_model, device)

                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.write(f"**üìå M√¥ t·∫£ s·∫£n ph·∫©m:** {caption}")
                st.write(f"**üîñ Lo·∫°i gi√†y nh·∫≠n di·ªán:** {shoe_type}")

                if heatmap_path:
                    st.image(heatmap_path, caption="üîç Grad-CAM++: Model t·∫≠p trung v√†o v√πng n√†o", use_container_width=True)
                else:
                    st.error("Kh√¥ng th·ªÉ t·∫°o Grad-CAM++! Vui l√≤ng th·ª≠ l·∫°i.")
            except Exception as e:
                st.error(f"L·ªói khi ph√¢n t√≠ch ·∫£nh: {str(e)}")
else:
    st.write("üì• Vui l√≤ng t·∫£i l√™n ·∫£nh gi√†y ƒë·ªÉ chatbot ph√¢n t√≠ch!")
